![Build](https://github.com/TobiasWaslowski/lingolift/actions/workflows/build.yml/badge.svg)

# lingolift

This application's goal is to enable people in learning languages while conversing with native speakers.
It is not a standalone language-learning app; instead, it aims to provide translations for everyday phrases
while explaining the grammatical structure and vocabulary of those sentences.

The application uses a mixture of Generative AI and Natural Language Processing (NLP) to perform translation
and sentence analysis. For example, both the idiomatic translation of the input sentence and the literal
translations are generated by GenAI (currently using the OpenAI API); however, the syntactical analysis of sentences
is largely achieved using the spaCy library.

## Overview

This codebase is roughly segmented into four parts:
The `backend`, the `telegram-bot`, the `frontend` and the `shared` package.
The `frontend` and `telegram-bot` are both clients for the `backend` API, which is the core of this application.
The `shared` package provides functionality that is shared between all parts of the application, for example a
HTTP client powered by `aiohttp` to deliver blazing fast requests, ensuring minimal wait times for the user.
It further contains models for all tasks performed (like the `translation` or `syntactical analysis`: This enables
type safety across the entire application, without which this kind of structure would be impossible to maintain.

The `backend` can be run as a local webserver powered by Flask; this is a relic from the prototyping stage of this
project, but it is still very convenient for local testing. However, for staging and production, the `backend` runs
entirely serverless on AWS Lambda, abstracted behind an API Gateway.

The frontend is currently hosted on the [Streamlit Community Cloud](https://streamlit.io/cloud) and is available for
testing [here](https://grammr.streamlit.app).
The Telegram bot can run on any low-powered machine; I'm personally using my Raspberry Pi to host it as of now;
you can try it out [here](https://t.me/lingolift_bot).

## On Generative AI

Since the public release of the OpenAI API, a lot of language apps (and startups in general) that effectively sell
GPT-Wrappers have sprung up left and right. I'm not a massive fan of this trend. To be completely honest, I feel
it is somewhat lazy at best and dishonest at worst to build an application that is more or less a massive API call 
and call it an "AI-powered learning application."

That being said, there are some things that you can do with Generative AI that are genuinely useful.
For instance, being able to provide the literal translation of every word in a sentence is interesting; this couldn't
be achieved by just using a dictionary; handling the ambiguous nature of words in different contexts is an extremely
complex task that is made significantly easier by using Generative AI.

The /syntactical-analysis endpoint creates an analysis of the sentence with spaCy using Universal POS tags.
There are some challenges around rendering this information, which largely belongs to the complex domain of
computational linguistics, in a way that is comprehensible to an average end-user.

If you're interested in reading about POS tagging and NLP in a broader sense, you can check out the following links:

https://universaldependencies.org/format.html#morphological-annotation

https://universaldependencies.org/u/feat/Degree.html

https://spacy.io/api/morphology#morphanalysis

https://www.nltk.org/
