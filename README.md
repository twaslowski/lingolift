![Build](https://github.com/TobiasWaslowski/lingolift/actions/workflows/build.yml/badge.svg)

# lingolift

This application's goal is to enable people in learning languages while conversing with native speakers.
It is not a standalone language-learning app; instead, it aims to provide translations for everyday phrases
while explaining the grammatical structure and vocabulary of those sentences.

The application uses a mixture of Generative AI and Natural Language Processing (NLP) to perform translation
and sentence analysis. For example, both the idiomatic translation of the input sentence and the literal
translations are generated by GenAI (currently using the OpenAI API); however, the syntactical analysis of sentences
is largely achieved using the spaCy library.

## Overview

This codebase is roughly segmented into four parts:
The `backend`, the `telegram-bot`, the `frontend` and the `shared` package.
The `frontend` and `telegram-bot` are both clients for the `backend` API, which is the core of this application.
The `shared` package provides functionality that is shared between all parts of the application, for example a
HTTP client powered by `aiohttp` to deliver blazing fast requests, ensuring minimal wait times for the user.
It further contains models for all tasks performed (like the `translation` or `syntactical analysis`: This enables
type safety across the entire application, without which this kind of structure would be impossible to maintain.

The `backend` can be run as a local webserver powered by Flask; this is a relic from the prototyping stage of this
project, but it is still very convenient for local testing. However, for staging and production, the `backend` runs
entirely serverless on AWS Lambda, abstracted behind an API Gateway.

The frontend is currently hosted on the [Streamlit Community Cloud](https://streamlit.io/cloud) and is available for
testing [here](https://grammr.streamlit.app).
The Telegram bot can run on any low-powered machine; I'm personally using my Raspberry Pi to host it as of now;
you can try it out [here](https://t.me/lingolift_bot).

## On Generative AI

Since the public release of the OpenAI API, a lot of language apps (and startups in general) that effectively sell
GPT-Wrappers have sprung up left and right. I'm not a massive fan of this trend. To be completely honest, I feel
it is somewhat lazy at best and dishonest at worst to build an application that is more or less a massive API call
and call it an "AI-powered learning application."

That being said, there are some things that you can do with Generative AI that are genuinely useful.
For instance, being able to provide the literal translation of every word in a sentence is interesting; this couldn't
be achieved by just using a dictionary; handling the ambiguous nature of words in different contexts is an extremely
complex task that is made significantly easier by using Generative AI.

Additionally, Generative AI (anecdotally, though I plan on benchmarking) performs substantially better than
[Lingua](https://github.com/pemistahl/lingua-py) at Language Detection tasks for extremely short sentences.
This is very useful; in cases like this, a hybrid approach of using Generative AI for shorter sentences and
probabilistic, more specialised models for other cases seems to be the best approach.

## NLP: Further Reading

The /syntactical-analysis endpoint creates an analysis of the sentence with spaCy using traditional NLP techniques.
Some of the goals are to show _why_ a word is inflected (incidentally, all the languages I'm focussing on right now
happen to be strongly inflected) in a certain way; for example, when saying _ein großer Bär_ in German, the word
_großer_ is an inflected adjective, and its inflection depends on the word it refers to, which is _Bär_ in this case.
Since _Bär_ is a masculine noun, _großer_ is inflected in the masculine nominative singular form.

<figure>
<img src="https://deutschlernerblog.de/wp-content/uploads/2015/11/Adjektivdeklination_bestimmter_unbestimmter_Artikel_ohne_Artikel_Plural.png" alt="drawing" width="700"/>
<figcaption>Source: https://deutschlernerblog.de/</figcaption>
</figure>

For people like me, who like to understand _why_ things work in a certain way, this just might be useful information.
Similarly, explaining _why_ a mistake you made is wrong might be very interesting.

### Caveats

Natural Language Processing is a very complex field, and I'm not exactly an expert in it.
One challenge is to render part-of-speech tagging, which is a huge part of what I'm doing right now, in a way that
is understandable to an average user. This challenge is made even more difficult by the fact that different languages
with different grammars may carry different learning challenges, so while this application supports a lot of languages
as of now, mileage may vary strongly on the NLP side of things.

If you're interested in reading about POS tagging and NLP in a broader sense, you can check out the following links:

https://universaldependencies.org/format.html#morphological-annotation

https://universaldependencies.org/u/feat/Degree.html

https://spacy.io/api/morphology#morphanalysis

https://www.nltk.org/
